{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "THOMAS MCDONNELL QUANT TRADING STRATEGIES HOMEWORK 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import quandl\n",
    "import functools\n",
    "import seaborn as sns\n",
    "import plotnine as p9\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "from tqdm import tqdm\n",
    "from pandas import DateOffset\n",
    "\n",
    "import warnings\n",
    "\n",
    "# Suppress the warning\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Worked with Sean Lin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "FR = pd.read_csv(\"C:/Users/thoma/Downloads/ZACKS_FR_2_f40c6a304f87d9f492c1f21839d474e2\\ZACKS_FR_2_f40c6a304f87d9f492c1f21839d474e2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "FR['per_end_date'] = pd.to_datetime(FR['per_end_date'])\n",
    "start_date = datetime(2014, 6, 1)\n",
    "FR = FR[FR['per_end_date'] >= start_date]\n",
    "end_date = datetime(2022, 1, 31)\n",
    "FR = FR[FR['per_end_date'] <= end_date]\n",
    "FR = FR.set_index('ticker')\n",
    "\n",
    "#Drop all of the tickers that don't have quarterly data\n",
    "FR = FR[FR['per_type'] == 'Q']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "FC = pd.read_csv(\"C:/Users/thoma\\Downloads\\ZACKS_FC_2_76e4bece47ce87cb8f221f639c7f829b/ZACKS_FC_2_76e4bece47ce87cb8f221f639c7f829b.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "FC = FC[['ticker','zacks_sector_code', 'per_end_date', 'filing_date']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "FC = FC.drop_duplicates(subset = 'ticker')\n",
    "\n",
    "#Drop all tickers in the finance, industry and auto sector\n",
    "\n",
    "FC = FC[~FC['zacks_sector_code'].isin([5.0, 13.0])]\n",
    "FC = FC.set_index('ticker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_tickers = set(FC.index).intersection(set(FR.index))\n",
    "FR = FR.loc[common_tickers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "FR['tot_debt_tot_equity'] = pd.to_numeric(FR['tot_debt_tot_equity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = FR.groupby('ticker')\n",
    "\n",
    "# Count the number of rows where tot_debt_tot_equity is greater than 0.1\n",
    "counts = grouped['tot_debt_tot_equity'].apply(lambda x: (x > 0.1).sum())\n",
    "\n",
    "# Filter out the tickers that don't have more than 85% of their rows with tot_debt_tot_equity greater than 0.1\n",
    "FR = grouped.filter(lambda x: (x['tot_debt_tot_equity'] > 0.1).sum() > len(x)*.85)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "FR = FR.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "FC = pd.read_csv(\"C:/Users/thoma\\Downloads\\ZACKS_FC_2_76e4bece47ce87cb8f221f639c7f829b/ZACKS_FC_2_76e4bece47ce87cb8f221f639c7f829b.csv\")\n",
    "FC = FC[['ticker', 'per_type','per_end_date', 'filing_date', 'tot_lterm_debt', 'net_lterm_debt', 'eps_diluted_net']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "FC = FC[FC['per_type'] == 'Q']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "FC['per_end_date'] = pd.to_datetime(FC['per_end_date'])\n",
    "FC['filing_date'] = pd.to_datetime(FC['filing_date'])\n",
    "merged_df = pd.merge(FR, FC, on=['per_end_date', 'ticker'])\n",
    "merged_df = merged_df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = merged_df.set_index('ticker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = merged_df.dropna(subset=['filing_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PSTV', 'KEYS', 'BGC', 'CST', 'FBIO', 'CTLP', 'PVG', 'CNX', 'PAY.',\n",
       "       'ALYE',\n",
       "       ...\n",
       "       'FUL', 'ALB', 'GEVO', 'OVRL', 'GNCMA', 'ISCB.', 'CXDC', 'MVNR.', 'XRX',\n",
       "       'SNDK'],\n",
       "      dtype='object', name='ticker', length=1892)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_tickers = merged_df.index.unique()\n",
    "unique_tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1892/1892 [00:02<00:00, 824.00it/s]\n"
     ]
    }
   ],
   "source": [
    "ticker_counts = {}\n",
    "for ticker in tqdm(unique_tickers):\n",
    "    # Get the number of rows for the current ticker\n",
    "    num_rows = merged_df.loc[merged_df.index == ticker].shape[0]\n",
    "    # Add the ticker and number of rows to the dictionary\n",
    "    ticker_counts[ticker] = num_rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop all tickers where they dont have at least 31 instances of data\n",
    "tickers_to_drop = [ticker for ticker in ticker_counts if ticker_counts[ticker] != 31]\n",
    "\n",
    "# Drop rows where the 'ticker' column is in the list of tickers to drop\n",
    "merged_df = merged_df[~merged_df.index.isin(tickers_to_drop)]\n",
    "FR\n",
    "unique_tickers = merged_df.index.unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers_to_remove = ['SWIOU', 'GEF.B' 'SENEB', 'BUKS', 'NUVR', 'INRD', 'TMS.', 'GBCS', 'UNIR', 'JANL', 'STCC', 'SMID', 'TPCS', 'TDSNA', 'BVHBB', 'BGSF']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = [x for x in unique_tickers if x not in tickers_to_remove]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I have a list of tickers whose data I will be taking to calculate the financial ratios. All of the work below here is about pulling in ZACKs dataframes and extracting all of the data. \n",
    "\n",
    "For all ZACK tables that aren't FC I will also need to merge my data on the filing date again to ensure that I have a filing date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = merged_df.loc[tickers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = merged_df[['per_end_date', 'filing_date', 'tot_debt_tot_equity', 'ret_invst', 'net_lterm_debt', 'tot_lterm_debt', 'eps_diluted_net']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = merged_df[merged_df.index.isin(tickers)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dealing with Shares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "SHRS = pd.read_csv(\"C:/Users/thoma/Downloads/ZACKS_SHRS_2_99db6fa97ac677f3c0d45a9fa9a70196\\ZACKS_SHRS_2_99db6fa97ac677f3c0d45a9fa9a70196.csv\")\n",
    "SHRS = SHRS[['ticker', 'per_end_date', 'shares_out']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "SHRS = SHRS.set_index('ticker')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dealing with market value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "MKTV = pd.read_csv(\"C:/Users/thoma/Downloads/ZACKS_MKTV_2_ecb7f768974bbdd26964caefe2fd0378\\ZACKS_MKTV_2_ecb7f768974bbdd26964caefe2fd0378.csv\")\n",
    "MKTV = MKTV[['ticker', 'per_end_date', 'mkt_val']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "MKTV['per_end_date'] = pd.to_datetime(MKTV['per_end_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = pd.merge(filtered_df, MKTV, left_on = ['ticker', 'per_end_date'], right_on = ['ticker', 'per_end_date'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turning EPS all positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df.loc[:, 'eps_diluted_net'] = filtered_df.loc[:, 'eps_diluted_net'].where(filtered_df.loc[:, 'eps_diluted_net'] >= 0, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = filtered_df.set_index('ticker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df['filing_date'] = filtered_df['filing_date'] + DateOffset(days=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import price data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1012/1012 [07:29<00:00,  2.25it/s]\n"
     ]
    }
   ],
   "source": [
    "eod_price = pd.DataFrame()\n",
    "for ticker in tqdm(unique_tickers):\n",
    "    df =  quandl.get_table('QUOTEMEDIA/PRICES', ticker = [ticker], api_key = 'uoxc6V3s61czWuHoGLcs',\n",
    "                    qopts = { 'columns': ['ticker', 'date', 'adj_close'] }, \n",
    "                    date = { 'gte': '2014-08-01', 'lte': '2022-02-01' }, \n",
    "                     paginate=True)\n",
    "    eod_price = eod_price.append(df)\n",
    "eod_price = eod_price.set_index('date')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "eod_price = eod_price.sort_values(by='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = filtered_df.sort_values(by = 'filing_date')\n",
    "filtered_df['date'] = filtered_df['filing_date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "n =pd.merge_asof(eod_price, filtered_df, by = 'ticker', left_on = 'date', right_on = 'date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = n['ticker'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = n.set_index('ticker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "n['net_lterm_debt'] = n['net_lterm_debt'].fillna(n['tot_lterm_debt'])\n",
    "n['net_lterm_debt'] = n['net_lterm_debt'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 972/972 [03:18<00:00,  4.89it/s]\n"
     ]
    }
   ],
   "source": [
    "for ticker in tqdm(n.index.unique()):\n",
    "    if n.loc[ticker].isna().any().any():\n",
    "        n = n.drop(ticker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = n.index.unique().tolist()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loop to get my ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = n.loc[tickers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date', 'adj_close', 'per_end_date', 'filing_date',\n",
       "       'tot_debt_tot_equity', 'ret_invst', 'net_lterm_debt', 'tot_lterm_debt',\n",
       "       'eps_diluted_net', 'mkt_val'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LLY = n.loc['LLY']\n",
    "LLY.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 280/280 [00:04<00:00, 56.69it/s]\n"
     ]
    }
   ],
   "source": [
    "f = pd.DataFrame()\n",
    "for ticker in tqdm(tickers):\n",
    "    df = n.loc[ticker]\n",
    "    df = df.merge(df, left_on='per_end_date', right_on='date', how = 'outer').ffill()\n",
    "    df = df.rename(columns = {'adj_close_y': 'per_end_price'})\n",
    "    df['debt_to_market_cap'] = df['tot_debt_tot_equity_x']*df['per_end_price']/df['adj_close_x']\n",
    "    df['price_to_earnings'] = df['adj_close_x']/df['eps_diluted_net_x']\n",
    "    df['R'] = (df['ret_invst_x']*(df['net_lterm_debt_y'] + (df['mkt_val_x'])))\n",
    "    df['ROI'] = df['R']/(df['net_lterm_debt_y']+df['mkt_val_x']*df['adj_close_x']/df['per_end_price']) \n",
    "    df['ticker'] = ticker\n",
    "    df = df[['date_x', 'adj_close_x', 'debt_to_market_cap', 'price_to_earnings', 'ROI', 'ticker']]\n",
    "    df = df.rename(columns = {'date_x': 'date', 'adj_close_x': 'price'})\n",
    "    df = df.drop_duplicates(subset = 'date')\n",
    "    f = df.append(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = f.set_index('ticker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.to_csv('hw_3_ratio_data.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "306c8db229f0a89c06d03772a1eff5479204b8baa09cdbdfc80c0ee3ff96995d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
